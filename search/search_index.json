{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"frac_blp","text":"<p>FRAC for macro-BLP (Salanie-Wolak).</p> <ul> <li>Github repository: https://github.com/bsalanie/frac-blp/</li> <li>Documentation https://bsalanie.github.io/frac-blp/</li> </ul>"},{"location":"index.html#overview","title":"Overview","text":"<p>The package estimates a second-order approximation to the macro BLP model with random coefficients using the FRAC method of Salanie and Wolak. </p> <p>At this early stage, the package only implements the basic version of the model without demographics. </p> <p>The user should be familiar with the macro BLP model (Berry, Levinsohn, and Pakes, 1995). We use very similar notation to that of Conlon and Gortmaker in their <code>pyblp</code> package.</p> <p>The inputs are:</p> <ul> <li><code>T</code>: the number of markets </li> <li><code>J</code>: the number of products per market</li> </ul> <p>The data must contain <code>N=T*J</code> observations, corresponding to all products in all markets. The observations should be ordered by market, i.e., the first <code>J</code> rows correspond to market 1, the next <code>J</code> rows to market 2, etc.</p> <p>The user must provide the following data matrices:</p> <ul> <li><code>Z</code>: a matrix of instruments, to which the program will add a constant</li> <li><code>shares</code>: a <code>N</code>-vector of market shares.</li> <li> <p>the regressors as a Pandas data frame with <code>N</code> rows. The program will construct the following Numpy matrices from the data frame:</p> </li> <li> <p><code>X1_exo</code>, the matrix of exogenous variables with fixed coefficients, using the column names in <code>names_X1_exo</code></p> </li> <li><code>X1_endo</code>, the matrix of endogenous variables with fixed coefficients, using the column names in <code>names_X1_endo</code></li> <li><code>X2_exo</code>, the matrix of exogenous variables with fixed coefficients, using the column names in <code>names_X2_exo</code></li> <li><code>X1_endo</code>, the matrix of endogenous variables with fixed coefficients, using the column names in <code>names_X2_endo</code>.</li> </ul> <p><code>names_X1_exo, names_X1_endo, names_X2_exo, names_X2_endo</code> are lists of strings provided by the user with the names of the columns in the data frame corresponding to each of these four types of variables.</p> <p>A constant term will not be added automatically, so if desired the user must include a column of ones in <code>X1_exo</code> and/or <code>X2_exo</code>.</p> <p><code>X2_exo</code> must be a subset of <code>X1_exo</code>, and <code>X2_endo</code> must be a subset of <code>X1_endo</code> (i.e., all variables with random coefficients must also have fixed coefficients). Any of these four matrices can be <code>None</code> if there are no variables of that type.</p> <p>The outputs are:</p> <ul> <li><code>betas</code>: the estimates on the variables with fixed coefficients <code>X1_exo</code>, <code>X1_endo</code> and the mean coefficients on the variables with random coefficients <code>X2_exo</code>, <code>X2_endo</code>, in that order.</li> <li><code>sigmas</code>: the standard deviations of the coefficients on the variables with random coefficients <code>X2_exo</code> and <code>X2_endo</code>, in that order.</li> </ul>"},{"location":"index.html#entering-the-data","title":"entering the data","text":"<p>The data must first be entered into a <code>FracNodemogRealData</code> object: <pre><code>from frac blp.frac classes import FracNodemogRealData\n\nfrac data = FracNodemogRealData(T, J,\n                            names_X1_exo,\n                            names_X1_endo,\n                            names_X2_exo,\n                            names_X2_endo,\n                            df_X1, \n                            Z, \n                            shares,\n                            )\n</code></pre> Then the model can be estimated with: <pre><code>from frac_blp.frac_nodemog import estimate\n\nbetabar, sigmas = frac nodemog estimate(frac data)\n</code></pre> <code>frac_demog_estimate</code> also has optional arguments to define the combinations of instruments and exogeneous variables to be used in the first stage:</p> <ul> <li>if <code>degree_Z=d</code> is provided, then all interactions of the columns of <code>Z</code> up to degree <code>d</code> will be used as instruments. </li> <li>if <code>degree_X1=d'</code> is provided, then all interactions of the columns of <code>X1_exo</code> up to degree <code>d'</code> will also be used, on their own and multiplied by the interactions of <code>Z</code>.</li> </ul> <p>The default has <code>degree_Z=2</code> and <code>degree_X1=2</code>.</p>"},{"location":"index.html#release-notes","title":"Release notes","text":""},{"location":"index.html#03-november-67-2025","title":"0.3 (November 67, 2025)","text":"<p>Improved interface for data input. Still no demographics.</p>"},{"location":"index.html#02-october-27-2025","title":"0.2 (October 27, 2025)","text":"<p>Improved README.</p>"},{"location":"index.html#01-october-26-2025","title":"0.1 (October 26, 2025)","text":"<p>First working version, no demographics.</p>"},{"location":"artificial_regressors.html","title":"artificial_regressors module","text":"<p>Helpers to construct Salani\u00e9-Wolak artificial regressors.</p>"},{"location":"artificial_regressors.html#frac_blp.artificial_regressors.make_K","title":"<code>make_K(X, shares)</code>","text":"<p>Build second-order Salani\u00e9-Wolak artificial regressors.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Product characteristics of shape <code>(n_products, n_x)</code>.</p> required <code>shares</code> <code>ndarray</code> <p>Product-level market shares of shape <code>(n_products,)</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Matrix <code>K</code> with shape <code>(n_products, n_x)</code>.</p> Source code in <code>frac_blp/artificial_regressors.py</code> <pre><code>def make_K(X: np.ndarray, shares: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Build second-order Salani\u00e9-Wolak artificial regressors.\n\n    Args:\n        X (np.ndarray): Product characteristics of shape ``(n_products, n_x)``.\n        shares (np.ndarray): Product-level market shares of shape ``(n_products,)``.\n\n    Returns:\n        np.ndarray: Matrix ``K`` with shape ``(n_products, n_x)``.\n    \"\"\"\n    eS_X = X.T @ shares\n    djm = eS_X - X / 2.0\n    return cast(np.ndarray, -djm * X)\n</code></pre>"},{"location":"artificial_regressors.html#frac_blp.artificial_regressors.make_K_and_y","title":"<code>make_K_and_y(X2, shares, J)</code>","text":"<p>Construct second-order regressors and the log-share LHS by market.</p> <p>Parameters:</p> Name Type Description Default <code>X2</code> <code>ndarray</code> <p>Regressors with random coefficients.</p> required <code>shares</code> <code>ndarray</code> <p>Observed market shares.</p> required <code>J</code> <code>int</code> <p>Number of products per market.</p> required <p>Returns:</p> Name Type Description <code>TwoArrays</code> <code>TwoArrays</code> <p><code>(K, y)</code> where <code>K</code> are artificial regressors and <code>y</code> is the</p> <code>TwoArrays</code> <p>stacked log share ratios.</p> Source code in <code>frac_blp/artificial_regressors.py</code> <pre><code>def make_K_and_y(X2: np.ndarray, shares: np.ndarray, J: int) -&gt; TwoArrays:\n    \"\"\"\n    Construct second-order regressors and the log-share LHS by market.\n\n    Args:\n        X2 (np.ndarray): Regressors with random coefficients.\n        shares (np.ndarray): Observed market shares.\n        J (int): Number of products per market.\n\n    Returns:\n        TwoArrays: ``(K, y)`` where ``K`` are artificial regressors and ``y`` is the\n        stacked log share ratios.\n    \"\"\"\n    n_obs = X2.shape[0]\n    n_x2 = X2.shape[1]\n    K = np.zeros((n_obs, n_x2))  # the artificial Salanie-Wolak regressors\n    y = np.zeros(n_obs)  # and the regression LHS\n\n    for t in range(n_obs // J):\n        this_market = slice(t * J, (t + 1) * J)\n        these_shares = shares[this_market]\n        sum_shares = these_shares.sum()\n        this_market_zero_share = 1.0 - sum_shares\n        this_X2 = X2[this_market, :]\n\n        # artificial regressors and LHS for Salanie-Wolak\n        K[this_market, :] = make_K(this_X2, these_shares)\n        y[this_market] = np.log(these_shares / this_market_zero_share)\n    return K, y\n</code></pre>"},{"location":"example_frac_nodemog.html","title":"examples/example_frac_nodemog module","text":"<p>Executable example demonstrating FRAC estimation without demographics. The example uses simulated data with all <code>X1</code> variables generated as N(0,1) iid; the user can modify the dimensions and other parameters of the simulation as desired.</p>"},{"location":"example_frac_nodemog.html#frac_blp.examples.example_frac_nodemog.run_example","title":"<code>run_example(T=50, J=20, n_X1_exo=1, n_X1_endo=1, n_X2_exo=0, n_X2_endo=1, n_Z=1, sigma_x=1.0, sigma_xi=1.0, rho_x_xi=np.sqrt(0.5), rho_x_z=np.sqrt(0.5), betas=np.array([-4.3, 1.0]), sigmas=np.array([1.0]))</code>","text":"<p>Simulates data and estimates it with FRAC without demographics; then repeats the estimation using the real data interface.</p> Source code in <code>frac_blp/examples/example_frac_nodemog.py</code> <pre><code>def run_example(\n    T: int = 50,\n    J: int = 20,\n    n_X1_exo: int = 1,\n    n_X1_endo: int = 1,\n    n_X2_exo: int = 0,\n    n_X2_endo: int = 1,\n    n_Z: int = 1,\n    sigma_x: float = 1.0,\n    sigma_xi: float = 1.0,\n    rho_x_xi: float = np.sqrt(0.5),\n    rho_x_z: float = np.sqrt(0.5),\n    betas: np.ndarray = np.array([-4.3, 1.0]),\n    sigmas: np.ndarray = np.array([1.0]),\n):\n    \"\"\"Simulates data and estimates it with FRAC without demographics;\n    then repeats the estimation using the real data interface.\n    \"\"\"\n    print_stars(\"Hello from frac_blp!\")\n    simulated_frac_data = simulate_frac_nodemog_data(\n        T=T,\n        J=J,\n        n_X1_exo=n_X1_exo,\n        n_X1_endo=n_X1_endo,\n        n_X2_exo=n_X2_exo,\n        n_X2_endo=n_X2_endo,\n        n_Z=n_Z,\n        sigma_x=sigma_x,\n        sigma_xi=sigma_xi,\n        rho_x_xi=rho_x_xi,\n        rho_x_z=rho_x_z,\n        betas=betas,\n        sigmas=sigmas,\n    )\n    print_stars(\"Simulated Data:\")\n    print(simulated_frac_data)\n\n    print_stars(\"Estimating with FRAC\")\n    _, _ = frac_nodemog_estimate(simulated_frac_data, degree_Z=3, degree_X1=3)\n\n    print_stars(\"Example with the real data interface:\")\n    df_X1 = pd.DataFrame(\n        np.column_stack(\n            (\n                simulated_frac_data.X1_exo,\n                simulated_frac_data.X1_endo,\n            )\n        ),\n        columns=simulated_frac_data.names_X1,\n    )\n    real_frac_data = FracNoDemogRealData(\n        T=simulated_frac_data.T,\n        J=simulated_frac_data.J,\n        df_X1=df_X1,\n        Z=simulated_frac_data.Z,\n        names_X1_exo=simulated_frac_data.names_X1_exo,\n        names_X1_endo=simulated_frac_data.names_X1_endo,\n        names_X2_exo=simulated_frac_data.names_X2_exo,\n        names_X2_endo=simulated_frac_data.names_X2_endo,\n        shares=simulated_frac_data.shares,\n    )\n    print_stars(\"Estimating with FRAC\")\n    _, _ = frac_nodemog_estimate(real_frac_data, degree_Z=3, degree_X1=3)\n</code></pre>"},{"location":"frac_classes.html","title":"frac_classes module","text":"<p>FRAC data containers and simulation utilities (no demographics).</p> <p>This module defines Pydantic models used to hold inputs and outputs for FRAC estimators without demographics, along with a parameter container for data simulation. Arrays are expected in stacked long format by market and product.</p> Conventions <ul> <li><code>T</code>: number of markets</li> <li><code>J</code>: number of products per market</li> <li><code>n_obs = T * J</code>: total product\u2013market observations</li> <li><code>X</code>: DataFrame with all regressors, shape <code>(n_obs, n_X)</code>    -  we use <code>names_X1_exo, names_X1_endo, names_X2_exo, names_X2_endo</code> to distinguish the variables of each type in <code>X</code></li> <li><code>X1</code>: regressors with fixed coefficients, shape <code>(n_obs, n_X1)</code></li> <li><code>X2</code>: regressors with random coefficients, shape <code>(n_obs, n_X2)</code>; must be a subset of <code>X1</code></li> <li><code>Z</code>: instrument matrix, shape <code>(n_obs, L)</code></li> </ul>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogRealData","title":"<code>FracNoDemogRealData</code>","text":"<p>               Bases: <code>_FracNoDemogBase</code></p> <p>Container for observed FRAC data without demographics.</p> <p>Inherits validation and properties from :class:<code>_FracNoDemogBase</code> and adds the observed market shares vector.</p> <p>Attributes:</p> Name Type Description <code>df_X1</code> <code>DataFrame</code> <p>DataFrame with regressors <code>X1</code> only</p> <code>Z</code> <code>ndarray</code> <p>Instrument matrix, shape <code>(n_obs, n_Z)</code>; we add the constant</p> <code>shares</code> <code>ndarray</code> <p>Observed product shares stacked by market, shape <code>(n_obs,)</code> with values in <code>[0, 1]</code> and per-market sums not exceeding <code>1</code>.</p> Source code in <code>frac_blp/frac_classes.py</code> <pre><code>class FracNoDemogRealData(_FracNoDemogBase):\n    \"\"\"Container for observed FRAC data without demographics.\n\n    Inherits validation and properties from :class:`_FracNoDemogBase` and adds\n    the observed market shares vector.\n\n    Attributes:\n        df_X1 (pd.DataFrame): DataFrame with regressors ``X1`` only\n        Z (np.ndarray): Instrument matrix, shape ``(n_obs, n_Z)``; we add the constant\n        shares (np.ndarray): Observed product shares stacked by market, shape\n            ``(n_obs,)`` with values in ``[0, 1]`` and per-market sums\n            not exceeding ``1``.\n    \"\"\"\n\n    df_X1: pd.DataFrame\n    Z: np.ndarray\n    shares: np.ndarray\n\n    # Computed design matrices picked from X by name groups\n\n    def get_X_by_names(self, names_str) -&gt; np.ndarray:\n        cols = getattr(self, names_str, []) or []\n        if len(cols) == 0:\n            return np.empty((self.n_obs, 0))\n        return cast(np.ndarray, self.df_X1.loc[:, cols].to_numpy().astype(np.float64))\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1_exo(self) -&gt; np.ndarray:\n        return cast(np.ndarray, self.get_X_by_names(\"names_X1_exo\"))\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1_endo(self) -&gt; np.ndarray:\n        return cast(np.ndarray, self.get_X_by_names(\"names_X1_endo\"))\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2_exo(self) -&gt; np.ndarray:\n        return cast(np.ndarray, self.get_X_by_names(\"names_X2_exo\"))\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2_endo(self) -&gt; np.ndarray:\n        return cast(np.ndarray, self.get_X_by_names(\"names_X2_endo\"))\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1(self) -&gt; np.ndarray:\n        return make_X(self.X1_exo, self.X1_endo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2(self) -&gt; np.ndarray:\n        return make_X(self.X2_exo, self.X2_endo)\n\n    @field_validator(\"df_X1\", mode=\"before\")\n    @classmethod\n    def _check_df1(cls, value):\n        if isinstance(value, pd.DataFrame):\n            return value\n        else:\n            raise ValidationError(\"df_X1 must be a pandas DataFrame or array-like.\")\n\n    @field_validator(\"Z\", mode=\"before\")\n    @classmethod\n    def _coerce_Z(cls, value):\n        return np.asarray(value)\n\n    @field_validator(\"shares\", mode=\"before\")\n    @classmethod\n    def _coerce_shares(cls, value: np.ndarray) -&gt; np.ndarray:\n        shares = np.asarray(value).ravel()\n        return shares\n\n    @model_validator(mode=\"after\")\n    def _validate_shares(self) -&gt; \"FracNoDemogRealData\":\n        shares = self.shares\n        if shares.ndim != 1:\n            raise ValueError(\"shares must be a 1D array.\")\n        if shares.shape[0] != self.n_obs:\n            raise ValueError(\n                f\"shares must have length {self.n_obs} (got {shares.shape[0]}).\"\n            )\n        if not np.all(np.isfinite(shares)):\n            raise ValueError(\"shares must contain only finite values.\")\n        if np.any((shares &lt; 0.0) | (shares &gt; 1.0)):\n            raise ValueError(\"shares must lie between 0 and 1.\")\n        T, J = self.T, self.J\n        for t in range(T):\n            market_shares = shares[t * J : (t + 1) * J]\n            if market_shares.sum() &gt; 1.0:\n                raise ValueError(\n                    f\"Shares in market {t} sum to more than 1 (got {market_shares.sum():.4f}).\"\n                )\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Summarize the observed dataset.\n\n        Returns:\n            str: Multi-line description with key parameters.\n        \"\"\"\n        desc = \"Observed Data for FRAC w/o demographics:\\n\"\n        desc += f\"  Number of markets (T): {self.T}\\n\"\n        desc += f\"  Products per market (J): {self.J}\\n\"\n        desc += f\"  Names of exogeneous variables with fixed coefficients: {self.names_X1_exo}\\n\"\n        desc += f\"  Names of endogeneous variables with fixed coefficients: {self.names_X1_endo}\\n\"\n        desc += f\"  Names of exogeneous variables with random coefficients: {self.names_X2_exo}\\n\"\n        desc += f\"  Names of endogeneous variables with random coefficients: {self.names_X2_endo}\\n\"\n        return desc\n</code></pre>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogRealData.__str__","title":"<code>__str__()</code>","text":"<p>Summarize the observed dataset.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Multi-line description with key parameters.</p> Source code in <code>frac_blp/frac_classes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Summarize the observed dataset.\n\n    Returns:\n        str: Multi-line description with key parameters.\n    \"\"\"\n    desc = \"Observed Data for FRAC w/o demographics:\\n\"\n    desc += f\"  Number of markets (T): {self.T}\\n\"\n    desc += f\"  Products per market (J): {self.J}\\n\"\n    desc += f\"  Names of exogeneous variables with fixed coefficients: {self.names_X1_exo}\\n\"\n    desc += f\"  Names of endogeneous variables with fixed coefficients: {self.names_X1_endo}\\n\"\n    desc += f\"  Names of exogeneous variables with random coefficients: {self.names_X2_exo}\\n\"\n    desc += f\"  Names of endogeneous variables with random coefficients: {self.names_X2_endo}\\n\"\n    return desc\n</code></pre>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData","title":"<code>FracNoDemogSimulatedData</code>","text":"<p>               Bases: <code>_FracNoDemogBase</code></p> <p>Container for simulated FRAC data without demographics.</p> <p>The regressors are generated as follows:</p> <ul> <li>for <code>X1_exo</code>: a constant, then <code>n_X1_exo</code>-1 variables N(0, 1) iid</li> <li>for <code>X1_endo</code>: $$ X_endo &amp;= \\sigma_x(\\rho_{xz} Z \\     &amp;+ \\sqrt{1 -\\rho_z ^ 2} \\     &amp;(\\rho_{x\\xi} \\xi / \\sigma_{\\xi}  +   N(0, 1-\\rho_{x\\xi}^2))) $$ where the \\(Z\\) are iid standard normal and \\(\\xi\\) is \\(N(0, \\sigma_{\\xi}^2)\\).</li> </ul> <p>Attributes:</p> Name Type Description <code>n_Z</code> <code>int</code> <p>Number of instruments apart from the constant</p> <code>sigma_x</code> <code>float</code> <p>Std. dev. used for regressor generation.</p> <code>sigma_xi</code> <code>float</code> <p>Std. dev. of unobserved product quality <code>xi</code>.</p> <code>rho_x_z</code> <code>float</code> <p>Correlation between <code>X</code> and <code>Z</code> (in <code>[-1, 1]</code>).</p> <code>rho_x_xi</code> <code>float</code> <p>Correlation between <code>X</code> and <code>xi</code> (in <code>[-1, 1]</code>).</p> <code>betas</code> <code>ndarray</code> <p>Fixed coefficients used for simulation, length <code>n_X1</code>.</p> <code>sigmas</code> <code>ndarray</code> <p>Std. devs of random coefficients, length <code>n_X2</code> and element-wise nonnegative..</p> Source code in <code>frac_blp/frac_classes.py</code> <pre><code>class FracNoDemogSimulatedData(_FracNoDemogBase):\n    \"\"\"Container for simulated FRAC data without demographics.\n\n\n    The regressors are generated as follows:\n\n    * for `X1_exo`: a constant, then `n_X1_exo`-1 variables N(0, 1) iid\n    * for `X1_endo`:\n    $$\n    X_endo &amp;= \\\\sigma_x(\\\\rho_{xz} Z \\\\\n        &amp;+ \\\\sqrt{1 -\\\\rho_z ^ 2} \\\\\n        &amp;(\\\\rho_{x\\\\xi} \\\\xi / \\\\sigma_{\\\\xi}  +   N(0, 1-\\\\rho_{x\\\\xi}^2)))\n    $$\n    where the $Z$ are iid standard normal and $\\\\xi$ is $N(0, \\\\sigma_{\\\\xi}^2)$.\n\n    Attributes:\n        n_Z (int): Number of instruments apart from the constant\n        sigma_x (float): Std. dev. used for regressor generation.\n        sigma_xi (float): Std. dev. of unobserved product quality ``xi``.\n        rho_x_z (float): Correlation between ``X`` and ``Z`` (in ``[-1, 1]``).\n        rho_x_xi (float): Correlation between ``X`` and ``xi`` (in ``[-1, 1]``).\n        betas (np.ndarray): Fixed coefficients used for simulation, length ``n_X1``.\n        sigmas (np.ndarray): Std. devs of random coefficients, length ``n_X2`` and\n            element-wise nonnegative..\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    # Caches to ensure one-time generation per instance\n    _X_cache: pd.DataFrame | None = PrivateAttr(default=None)\n    _Z_cache: np.ndarray | None = PrivateAttr(default=None)\n    _xi_var_cache: np.ndarray | None = PrivateAttr(default=None)\n    _shares_cache: np.ndarray | None = PrivateAttr(default=None)\n\n    n_Z: int = 1\n    sigma_x: float = 1.0\n    sigma_xi: float = 1.0\n    rho_x_z: float = float(np.sqrt(0.5))\n    rho_x_xi: float = float(np.sqrt(0.5))\n    betas: np.ndarray = np.array([-4.3, 1.0])\n    sigmas: np.ndarray = np.array([1.0])\n\n    @field_validator(\"T\", \"J\", mode=\"before\")\n    @classmethod\n    def _validate_positive_int(cls, value: int) -&gt; int:\n        if value &lt;= 0:\n            raise ValueError(\"T and J must be strictly positive integers.\")\n        return int(value)\n\n    @field_validator(\"betas\", \"sigmas\", mode=\"before\")\n    @classmethod\n    def _coerce_vectors(cls, value: np.ndarray) -&gt; np.ndarray:\n        # Coerce to a 1-D array; avoid squeeze creating 0-D for 1x1 inputs.\n        return np.asarray(value).ravel()\n\n    @field_validator(\"sigma_xi\", \"sigma_x\")\n    @classmethod\n    def _validate_sigma_xi(cls, v: float):\n        if not np.isfinite(v):\n            raise ValueError(\"sigma_x and sigma_xi must be finite.\")\n        if v &lt; 0.0:\n            raise ValueError(\"sigma_x and sigma_xi must be non-negative.\")\n        return float(v)\n\n    @model_validator(mode=\"after\")\n    def _validate_betas_length(self) -&gt; \"FracNoDemogSimulatedData\":\n        if self.betas.ndim != 1:\n            raise ValueError(\"betas must be a 1D array.\")\n        if self.betas.shape[0] != self.n_X1:\n            raise ValueError(\n                f\"betas must have length  n_X1 = {self.n_X1} (got {self.betas.shape[0]}).\"\n            )\n        return self\n\n    @model_validator(mode=\"after\")\n    def _validate_sigmas_length(self) -&gt; \"FracNoDemogSimulatedData\":\n        expected_n2 = int(self.n_X2_exo) + int(self.n_X2_endo)\n        if self.sigmas.ndim != 1:\n            raise ValueError(\"sigmas must be a 1D array.\")\n        if self.sigmas.shape[0] != expected_n2:\n            raise ValueError(\n                f\"sigmas must have length n_X2_exo + n_X2_endo = {expected_n2} (got {self.sigmas.shape[0]}).\"\n            )\n        return self\n\n    @field_validator(\"sigmas\")\n    @classmethod\n    def _validate_vector_nonneg(cls, v: np.ndarray) -&gt; np.ndarray:\n        if not np.all(np.isfinite(v)):\n            raise ValueError(\"sigmas must contain only finite values.\")\n        if np.any(v &lt; 0.0):\n            raise ValueError(\"all components of sigmas must be non-negative.\")\n        return v\n\n    @field_validator(\"rho_x_z\", \"rho_x_xi\")\n    @classmethod\n    def _validate_rho(cls, v: float, info):\n        if not np.isfinite(v):\n            raise ValueError(f\"{info.field_name} must be finite.\")\n        if v &lt; -1.0 or v &gt; 1.0:\n            raise ValueError(f\"{info.field_name} must be between -1 and 1.\")\n        return float(v)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def xi_var(self) -&gt; np.ndarray:\n        \"\"\"Realizations of the product effects ``xi``, shape ``(n_obs,)``.\n\n        Returns:\n            np.ndarray: Realizations of ``xi``.\n        \"\"\"\n        if self._xi_var_cache is not None:\n            return self._xi_var_cache\n        rng = np.random.default_rng(seed=None)\n        xi_vals = cast(np.ndarray, rng.normal(0.0, self.sigma_xi, size=self.n_obs))\n        self._xi_var_cache = xi_vals\n        return self._xi_var_cache\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def Z(self) -&gt; np.ndarray:\n        \"\"\"Realizations of the instruments ``Z``, shape ``(n_obs, n_Z)``.\n        They are a constant plus ``n_Z`` iid N(0, 1) variables.\n\n        Returns:\n            np.ndarray: Realizations of ``Z``.\n        \"\"\"\n        if self._Z_cache is not None:\n            return self._Z_cache\n        rng = np.random.default_rng(seed=None)\n        Z_vals = rng.normal(0.0, 1.0, size=(self.n_obs, self.n_Z))\n        Z_full = np.column_stack((np.ones(self.n_obs), Z_vals))\n        self._Z_cache = Z_full\n        return self._Z_cache\n\n    @computed_field(return_type=pd.DataFrame)  # type: ignore[misc]\n    @property\n    def X(self) -&gt; pd.DataFrame:\n        \"\"\"Create the DataFrame `X` with all regressors.\n\n        Returns:\n            pd.DataFrame: DataFrame with all regressors.\n        \"\"\"\n        if self._X_cache is not None:\n            return self._X_cache\n\n        rng = np.random.default_rng(seed=None)\n        n_obs, sigma_x, sigma_xi = self.n_obs, self.sigma_x, self.sigma_xi\n        xi_var, rho_x_z, rho_x_xi = self.xi_var, self.rho_x_z, self.rho_x_xi\n        n_X1_exo, n_X1_endo = self.n_X1_exo, self.n_X1_endo\n        X1_exo = np.column_stack(\n            (np.ones(n_obs), rng.normal(0, sigma_x, size=(n_obs, n_X1_exo - 1)))\n        )\n        root1 = float(np.sqrt(1.0 - rho_x_z**2))\n        root2 = float(np.sqrt(1.0 - rho_x_xi**2))\n        X1_endo = np.empty((n_obs, n_X1_endo))\n        for i in range(n_X1_endo):\n            X1_endo[:, i] = sigma_x * (\n                rho_x_z * self.Z[:, i + 1]  # skip the constant instrument\n                + root1\n                * (\n                    rho_x_xi * xi_var / sigma_xi\n                    + root2 * rng.normal(0.0, 1.0, size=n_obs)\n                )\n            )\n        X_mat = make_X(X1_exo, X1_endo)\n        df_X = pd.DataFrame(X_mat, columns=self.names_X1)\n        print(df_X.head())\n        self._X_cache = df_X\n        return self._X_cache\n\n    # Computed design matrices generated according to simulation parameters\n    def get_X1_piece(self, start: int, n: int) -&gt; np.ndarray:\n        n_obs = self.n_obs\n        if n == 0:\n            return np.empty((n_obs, 0)).astype(np.float64)\n        else:\n            return cast(\n                np.ndarray, self.X.to_numpy()[:, start : (start + n)].astype(np.float64)\n            )\n\n    def get_X2_piece(self, names: list[str]) -&gt; np.ndarray:\n        if len(names) == 0:\n            return np.empty((self.n_obs, 0))\n        cols = self.X[names].values.astype(np.float64)\n        return cast(np.ndarray, cols)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1_exo(self) -&gt; np.ndarray:\n        return self.get_X1_piece(0, self.n_X1_exo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1_endo(self) -&gt; np.ndarray:\n        return self.get_X1_piece(self.n_X1_exo, self.n_X1_endo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2_exo(self) -&gt; np.ndarray:\n        return self.get_X2_piece(self.names_X2_exo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2_endo(self) -&gt; np.ndarray:\n        return self.get_X2_piece(self.names_X2_endo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X1(self) -&gt; np.ndarray:\n        return make_X(self.X1_exo, self.X1_endo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def X2(self) -&gt; np.ndarray:\n        return make_X(self.X2_exo, self.X2_endo)\n\n    @computed_field(return_type=np.ndarray)  # type: ignore[misc]\n    @property\n    def shares(self) -&gt; np.ndarray:\n        \"\"\"Simulated market shares using sparse Gaussian quadrature.\n\n        Returns:\n            np.ndarray: Simulated shares stacked across markets, shape ``(n_obs,)``.\n        \"\"\"\n        if self._shares_cache is not None:\n            return self._shares_cache\n        shares_vals = self.compute_shares()\n        self._shares_cache = shares_vals\n        return self._shares_cache\n\n    def compute_shares(self) -&gt; np.ndarray:\n        \"\"\"Compute simulated market shares via sparse Gaussian quadrature.\n\n        The routine integrates over the distribution of random coefficients\n        using a sparse Gaussian grid. For each market, it computes choice\n        probabilities conditional on nodes and averages them with quadrature\n        weights.\n\n        Returns:\n            np.ndarray: Simulated shares stacked across all markets with shape\n            ``(n_obs,)``.\n        \"\"\"\n        T, J = self.T, self.J\n        sigmas = self.sigmas\n        X1 = self.X1\n        X2 = self.X2\n        n_X2 = X2.shape[1]\n        n_obs = T * J\n        mean_utils = X1 @ self.betas + self.xi_var.reshape(n_obs)\n        shares = np.zeros(n_obs)\n        # Handle the degenerate case n_X2 == 0 (no random coefficients):\n        if n_X2 == 0:\n            zero_share = np.zeros(self.T)\n            for t in range(T):\n                this_market = slice(t * J, (t + 1) * J)\n                these_mean_utils = mean_utils[this_market]\n                max_util = np.max(these_mean_utils)\n                shifted = these_mean_utils - max_util\n                exp_utils = np.exp(shifted)\n                denom = np.exp(-max_util) + np.sum(exp_utils)\n                shares[this_market] = exp_utils / denom\n                zero_share[t] = 1.0 - shares[this_market].sum()\n        else:\n            nodes, weights = setup_sparse_gaussian(n_X2, 17)\n            nodes_T = nodes.T  # shape (n_X2, n_nodes)\n            weighted_nodes = nodes_T * sigmas.reshape((-1, 1))  # shape (n_X2, n_nodes)\n            zero_share = np.zeros(self.T)\n            for t in range(T):\n                this_market = slice(t * J, (t + 1) * J)\n                these_mean_utils = mean_utils[this_market]\n                this_X2 = X2[this_market, :]  # (J, n_X2)\n\n                randoms = this_X2 @ weighted_nodes  # (J, n_nodes)\n                random_utils = randoms + these_mean_utils.reshape((-1, 1))\n                max_util = np.max(random_utils, axis=0).astype(np.float64)\n                shifted_utils = (random_utils - max_util).astype(np.float64)\n                exp_utils = np.exp(shifted_utils)\n                denom = np.exp(-max_util) + np.sum(exp_utils, axis=0)\n                # breakpoint()\n                shares[this_market] = exp_utils @ (weights / denom)\n                zero_share[t] = 1.0 - shares[this_market].sum()\n\n        print_stars(\n            dedent(\n                f\"\"\"\n                    Data generation completed; the average zero share is {zero_share.mean():.4f}\n                    \"\"\"\n            )\n        )\n        return shares\n\n    def __str__(self) -&gt; str:\n        \"\"\"Summarize the simulated dataset.\n\n        Returns:\n            str: Multi-line description with key Data.\n        \"\"\"\n        desc = \"Simulated Data for FRAC w/o demographics:\\n\"\n        desc += f\"  Number of markets (T): {self.T}\\n\"\n        desc += f\"  Products per market (J): {self.J}\\n\"\n        desc += f\"  Names of exogeneous variables with fixed coefficients: {self.names_X1_exo}\\n\"\n        desc += f\"  Names of endogeneous variables with fixed coefficients: {self.names_X1_endo}\\n\"\n        desc += f\"  Names of exogeneous variables with random coefficients: {self.names_X2_exo}\\n\"\n        desc += f\"  Names of endogeneous variables with random coefficients: {self.names_X2_endo}\\n\"\n        desc += f\"  Betas: {self.betas}\\n\"\n        desc += f\"  Sigmas: {self.sigmas}\\n\"\n        return desc\n</code></pre>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.X","title":"<code>X</code>  <code>property</code>","text":"<p>Create the DataFrame <code>X</code> with all regressors.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: DataFrame with all regressors.</p>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.Z","title":"<code>Z</code>  <code>property</code>","text":"<p>Realizations of the instruments <code>Z</code>, shape <code>(n_obs, n_Z)</code>. They are a constant plus <code>n_Z</code> iid N(0, 1) variables.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Realizations of <code>Z</code>.</p>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.shares","title":"<code>shares</code>  <code>property</code>","text":"<p>Simulated market shares using sparse Gaussian quadrature.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Simulated shares stacked across markets, shape <code>(n_obs,)</code>.</p>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.xi_var","title":"<code>xi_var</code>  <code>property</code>","text":"<p>Realizations of the product effects <code>xi</code>, shape <code>(n_obs,)</code>.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Realizations of <code>xi</code>.</p>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.__str__","title":"<code>__str__()</code>","text":"<p>Summarize the simulated dataset.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Multi-line description with key Data.</p> Source code in <code>frac_blp/frac_classes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Summarize the simulated dataset.\n\n    Returns:\n        str: Multi-line description with key Data.\n    \"\"\"\n    desc = \"Simulated Data for FRAC w/o demographics:\\n\"\n    desc += f\"  Number of markets (T): {self.T}\\n\"\n    desc += f\"  Products per market (J): {self.J}\\n\"\n    desc += f\"  Names of exogeneous variables with fixed coefficients: {self.names_X1_exo}\\n\"\n    desc += f\"  Names of endogeneous variables with fixed coefficients: {self.names_X1_endo}\\n\"\n    desc += f\"  Names of exogeneous variables with random coefficients: {self.names_X2_exo}\\n\"\n    desc += f\"  Names of endogeneous variables with random coefficients: {self.names_X2_endo}\\n\"\n    desc += f\"  Betas: {self.betas}\\n\"\n    desc += f\"  Sigmas: {self.sigmas}\\n\"\n    return desc\n</code></pre>"},{"location":"frac_classes.html#frac_blp.frac_classes.FracNoDemogSimulatedData.compute_shares","title":"<code>compute_shares()</code>","text":"<p>Compute simulated market shares via sparse Gaussian quadrature.</p> <p>The routine integrates over the distribution of random coefficients using a sparse Gaussian grid. For each market, it computes choice probabilities conditional on nodes and averages them with quadrature weights.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Simulated shares stacked across all markets with shape</p> <code>ndarray</code> <p><code>(n_obs,)</code>.</p> Source code in <code>frac_blp/frac_classes.py</code> <pre><code>def compute_shares(self) -&gt; np.ndarray:\n    \"\"\"Compute simulated market shares via sparse Gaussian quadrature.\n\n    The routine integrates over the distribution of random coefficients\n    using a sparse Gaussian grid. For each market, it computes choice\n    probabilities conditional on nodes and averages them with quadrature\n    weights.\n\n    Returns:\n        np.ndarray: Simulated shares stacked across all markets with shape\n        ``(n_obs,)``.\n    \"\"\"\n    T, J = self.T, self.J\n    sigmas = self.sigmas\n    X1 = self.X1\n    X2 = self.X2\n    n_X2 = X2.shape[1]\n    n_obs = T * J\n    mean_utils = X1 @ self.betas + self.xi_var.reshape(n_obs)\n    shares = np.zeros(n_obs)\n    # Handle the degenerate case n_X2 == 0 (no random coefficients):\n    if n_X2 == 0:\n        zero_share = np.zeros(self.T)\n        for t in range(T):\n            this_market = slice(t * J, (t + 1) * J)\n            these_mean_utils = mean_utils[this_market]\n            max_util = np.max(these_mean_utils)\n            shifted = these_mean_utils - max_util\n            exp_utils = np.exp(shifted)\n            denom = np.exp(-max_util) + np.sum(exp_utils)\n            shares[this_market] = exp_utils / denom\n            zero_share[t] = 1.0 - shares[this_market].sum()\n    else:\n        nodes, weights = setup_sparse_gaussian(n_X2, 17)\n        nodes_T = nodes.T  # shape (n_X2, n_nodes)\n        weighted_nodes = nodes_T * sigmas.reshape((-1, 1))  # shape (n_X2, n_nodes)\n        zero_share = np.zeros(self.T)\n        for t in range(T):\n            this_market = slice(t * J, (t + 1) * J)\n            these_mean_utils = mean_utils[this_market]\n            this_X2 = X2[this_market, :]  # (J, n_X2)\n\n            randoms = this_X2 @ weighted_nodes  # (J, n_nodes)\n            random_utils = randoms + these_mean_utils.reshape((-1, 1))\n            max_util = np.max(random_utils, axis=0).astype(np.float64)\n            shifted_utils = (random_utils - max_util).astype(np.float64)\n            exp_utils = np.exp(shifted_utils)\n            denom = np.exp(-max_util) + np.sum(exp_utils, axis=0)\n            # breakpoint()\n            shares[this_market] = exp_utils @ (weights / denom)\n            zero_share[t] = 1.0 - shares[this_market].sum()\n\n    print_stars(\n        dedent(\n            f\"\"\"\n                Data generation completed; the average zero share is {zero_share.mean():.4f}\n                \"\"\"\n        )\n    )\n    return shares\n</code></pre>"},{"location":"frac_nodemog.html","title":"frac_nodemog module","text":"<p>FRAC estimation on macro-BLP, without demographics</p>"},{"location":"frac_nodemog.html#frac_blp.frac_nodemog.frac_nodemog_estimate","title":"<code>frac_nodemog_estimate(frac_data, degree_Z=2, degree_X1=2)</code>","text":"<p>Estimate FRAC parameters without demographics using two-stage least squares.</p> <p>Parameters:</p> Name Type Description Default <code>frac_data</code> <code>FracNoDemogData</code> <p>Data container with regressors, instruments, and simulated or empirical shares.</p> required <code>degree_Z</code> <code>int</code> <p>Degree of polynomial expansion for instruments. Default is 2.</p> <code>2</code> <code>degree_X1</code> <code>int</code> <p>Degree of polynomial expansion for exogenous regressors in X1. Default is 2.</p> <code>2</code> <p>Returns:</p> Name Type Description <code>TwoArrays</code> <code>TwoArrays</code> <p>Tuple <code>(betas_est, sigmas_est)</code> with fixed and random coefficient</p> <code>TwoArrays</code> <p>estimates, respectively.</p> Source code in <code>frac_blp/frac_nodemog.py</code> <pre><code>def frac_nodemog_estimate(\n    frac_data: FracNoDemogData,\n    degree_Z: int = 2,\n    degree_X1: int = 2,\n) -&gt; TwoArrays:\n    \"\"\"\n    Estimate FRAC parameters without demographics using two-stage least squares.\n\n    Args:\n        frac_data (FracNoDemogData): Data container with regressors, instruments, and\n            simulated or empirical shares.\n        degree_Z (int): Degree of polynomial expansion for instruments. Default is 2.\n        degree_X1 (int): Degree of polynomial expansion for exogenous regressors in X1.\n            Default is 2.\n\n    Returns:\n        TwoArrays: Tuple ``(betas_est, sigmas_est)`` with fixed and random coefficient\n        estimates, respectively.\n    \"\"\"\n    X1_exo = frac_data.X1_exo\n    X1, X2 = frac_data.X1.astype(np.float64), frac_data.X2.astype(np.float64)\n    J = frac_data.J\n    Z = frac_data.Z\n    names_X1 = frac_data.names_X1\n    names_X2 = frac_data.names_X2\n    shares = frac_data.shares\n    K, y = make_K_and_y(X2, shares, J)\n    K = K.astype(np.float64)\n    y = y.astype(np.float64)\n    n_X1 = X1.shape[1]\n    n_X2 = X2.shape[1]\n\n    # combine exogenous regressors and instruments\n    Z_full = make_Z_full(Z, X1_exo, degree_Z=degree_Z, degree_X1=degree_X1).astype(\n        np.float64\n    )\n\n    # project on the full set of instruments\n    y_hat, _, r2_y = proj_Z_full(y.reshape((frac_data.n_obs, 1)), Z_full)\n    K_hat, _, r2_K = proj_Z_full(K, Z_full)\n    X1_hat, _, r2_X1 = proj_Z_full(X1, Z_full)\n\n    # breakpoint()\n    print_stars(\n        f\"The first stage R2s of projecting on the full set of {Z_full.shape[1]} instruments are:\"\n    )\n    print(f\"    for y: {r2_y[0]:.3f}\")\n    for ix in range(n_X1):\n        print(f\"     for {names_X1[ix]}: {r2_X1[ix]:.3f}\")\n    for ix in range(n_X2):\n        print(f\"     for K_{names_X2[ix]}: {r2_K[ix]:.3f}\")\n    print(\"\\n\")\n\n    # run the second stage\n    RHS_proj = np.column_stack((X1_hat, K_hat))\n    betas_sigmas_est = spla.lstsq(RHS_proj, y_hat[:, 0])[0]\n    betas_est = betas_sigmas_est[:n_X1]\n    sigmas_squared_est = betas_sigmas_est[n_X1:]\n    if np.min(sigmas_squared_est) &lt; 0.0:\n        print_stars(\"\\n The variance estimates are\")\n        print(sigmas_squared_est)\n        bs_error_abort(\"We have a negative variance estimate!\")\n    sigmas_est = np.sqrt(sigmas_squared_est)\n\n    print_stars(\"The final estimates are:\")\n    for i in range(len(names_X1)):\n        print(f\"   beta1_{names_X1[i]}: {betas_est[i]:.3f}\")\n    for i in range(len(names_X2)):\n        print(f\"   sigma_{names_X2[i]}: {sigmas_est[i]:.3f}\")\n    return betas_est, sigmas_est\n</code></pre>"},{"location":"frac_utils.html","title":"frac_utils module","text":"<p>Utility helpers for building instruments and projections in FRAC.</p>"},{"location":"frac_utils.html#frac_blp.frac_utils.make_X","title":"<code>make_X(X_exo, X_endo)</code>","text":"<p>Combine exogenous and endogenous regressors into a single regressor matrix.</p> <p>Parameters:</p> Name Type Description Default <code>X_exo</code> <code>ndarray | None</code> <p>Exogenous regressors.</p> required <code>X_endo</code> <code>ndarray | None</code> <p>Endogenous regressors.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The concatenated regressor matrix.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>X_exo</code> and <code>X_endo</code> are <code>None</code>.</p> Source code in <code>frac_blp/frac_utils.py</code> <pre><code>def make_X(X_exo: np.ndarray | None, X_endo: np.ndarray | None) -&gt; np.ndarray:\n    \"\"\"\n    Combine exogenous and endogenous regressors into a single regressor matrix.\n\n    Args:\n        X_exo (np.ndarray | None): Exogenous regressors.\n        X_endo (np.ndarray | None): Endogenous regressors.\n\n    Returns:\n        np.ndarray: The concatenated regressor matrix.\n\n    Raises:\n        ValueError: If both `X_exo` and `X_endo` are ``None``.\n    \"\"\"\n    if X_exo is not None and X_endo is not None:\n        X = np.column_stack((X_exo, X_endo))\n    elif X_exo is not None:\n        X = X_exo\n    elif X_endo is not None:\n        X = X_endo\n    else:\n        raise ValueError(\"At least one of X_exo or X_endo must be provided.\")\n    return X\n</code></pre>"},{"location":"frac_utils.html#frac_blp.frac_utils.make_Z_full","title":"<code>make_Z_full(Z, X1_exo=None, degree_Z=2, degree_X1=2)</code>","text":"<p>Build a full set of polynomial instruments for FRAC without demographics.</p> <p>Parameters:</p> Name Type Description Default <code>Z</code> <code>ndarray</code> <p>Baseline instruments.</p> required <code>X1_exo</code> <code>ndarray | None</code> <p>Exogenous regressors without random coefficients.</p> <code>None</code> <code>degree_Z</code> <code>int</code> <p>Maximum degree applied to columns of <code>Z</code> (must be &gt;= 0).</p> <code>2</code> <code>degree_X1</code> <code>int</code> <p>Maximum degree applied to columns of <code>X1_exo</code>.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Instrument matrix whose columns enumerate every admissible</p> <code>ndarray</code> <p>combination of polynomial terms, preceded by a column of ones.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>degree_Z</code> is negative.</p> Source code in <code>frac_blp/frac_utils.py</code> <pre><code>def make_Z_full(\n    Z: np.ndarray,\n    X1_exo: np.ndarray | None = None,\n    degree_Z: int = 2,\n    degree_X1: int = 2,\n) -&gt; np.ndarray:\n    \"\"\"\n    Build a full set of polynomial instruments for FRAC without demographics.\n\n    Args:\n        Z (np.ndarray): Baseline instruments.\n        X1_exo (np.ndarray | None): Exogenous regressors without random coefficients.\n        degree_Z (int): Maximum degree applied to columns of ``Z`` (must be &gt;= 0).\n        degree_X1 (int): Maximum degree applied to columns of ``X1_exo``.\n\n    Returns:\n        np.ndarray: Instrument matrix whose columns enumerate every admissible\n        combination of polynomial terms, preceded by a column of ones.\n\n    Raises:\n        ValueError: If ``degree_Z`` is negative.\n    \"\"\"\n    if degree_Z &lt; 0:\n        raise ValueError(\"degree_Z must be non-negative.\")\n\n    n_obs, n_z = Z.shape\n    columns: list[np.ndarray] = [np.ones(n_obs)]\n\n    n_x1 = 0 if X1_exo is None else X1_exo.shape[1]\n    max_dx1 = degree_X1 if X1_exo is not None else 0\n\n    for d_z in range(degree_Z + 1):\n        z_indices = [None] if d_z == 0 else range(n_z)\n        for iz in z_indices:\n            base_z = np.ones(n_obs) if iz is None else Z[:, iz] ** d_z\n            # str_base_z = \" \" if iz is None else f\"Z[:, {iz}] ** {d_z} \"\n\n            for d_x1 in range(max_dx1 + 1):\n                x1_indices = [None] if d_x1 == 0 else range(n_x1)\n                for ix1 in x1_indices:\n                    if ix1 is None:\n                        term_x1 = np.ones(n_obs)\n                        # str_X1 = \"1 \"\n                    else:\n                        assert X1_exo is not None\n                        term_x1 = X1_exo[:, ix1] ** d_x1\n                        # str_X1 = f\"X1_exo[:, {ix1}] ** {d_x1} \"\n                    columns.append(base_z * term_x1)\n                    # print(f\"{iz=}, {d_z=}, {ix1=}, {d_x1=}\")\n                    # print(\"    \" + str_base_z + \" * \" + str_X1)\n\n    return np.column_stack(columns)\n</code></pre>"},{"location":"frac_utils.html#frac_blp.frac_utils.proj_Z_full","title":"<code>proj_Z_full(X, Z_full)</code>","text":"<p>Project each column of <code>X</code> onto <code>Z_full</code> and report fitted values.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Variables to project.</p> required <code>Z_full</code> <code>ndarray</code> <p>Instrument matrix used for the projections.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>tuple[np.ndarray, np.ndarray, np.ndarray]: <code>X_proj</code> with projected columns,</p> <code>ndarray</code> <p><code>coef</code> with least-squares coefficients, and <code>r2</code> with column-wise</p> <code>ndarray</code> <p>R-squared values.</p> Source code in <code>frac_blp/frac_utils.py</code> <pre><code>def proj_Z_full(\n    X: np.ndarray, Z_full: np.ndarray\n) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Project each column of ``X`` onto ``Z_full`` and report fitted values.\n\n    Args:\n        X (np.ndarray): Variables to project.\n        Z_full (np.ndarray): Instrument matrix used for the projections.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, np.ndarray]: ``X_proj`` with projected columns,\n        ``coef`` with least-squares coefficients, and ``r2`` with column-wise\n        R-squared values.\n    \"\"\"\n    EPS = 1e-12\n    n_x = X.shape[1]\n    X_proj = np.empty(X.shape)\n    coef = np.empty((Z_full.shape[1], n_x))\n    r2 = np.empty(n_x)\n    for ix in range(n_x):\n        x = X[:, ix]\n        coef_x = spla.lstsq(Z_full, x)[0]\n        x_proj = Z_full @ coef_x\n        X_proj[:, ix] = x_proj\n        coef[:, ix] = coef_x\n        var_x = np.var(x)\n        r2[ix] = 1.0 if var_x &lt; EPS else np.var(x_proj) / var_x\n    return X_proj, coef, r2\n</code></pre>"},{"location":"simulate_frac_nodemog_data.html","title":"simulate_frac_nodemog_data module","text":"<p>Helper script to simulate FRAC datasets used in tutorials.</p>"},{"location":"simulate_frac_nodemog_data.html#frac_blp.simulate_frac_nodemog_data.simulate_frac_nodemog_data","title":"<code>simulate_frac_nodemog_data(T=50, J=20, n_X1_exo=1, n_X1_endo=1, n_X2_exo=0, n_X2_endo=1, n_Z=1, sigma_x=1.0, sigma_xi=1.0, rho_x_xi=np.sqrt(0.5), rho_x_z=np.sqrt(0.5), betas=np.array([-4.3, 1.0]), sigmas=np.array([1.0]))</code>","text":"<p>Simulate FRAC data with endogenous random-coefficient regressors.</p> <p>Returns:</p> Name Type Description <code>FracNoDemogSimulatedData</code> <code>FracNoDemogSimulatedData</code> <p>Simulated dataset ready for FRAC estimation.</p> Source code in <code>frac_blp/simulate_frac_nodemog_data.py</code> <pre><code>def simulate_frac_nodemog_data(\n    T: int = 50,\n    J: int = 20,\n    n_X1_exo: int = 1,\n    n_X1_endo: int = 1,\n    n_X2_exo: int = 0,\n    n_X2_endo: int = 1,\n    n_Z: int = 1,\n    sigma_x: float = 1.0,\n    sigma_xi: float = 1.0,\n    rho_x_xi: float = np.sqrt(0.5),\n    rho_x_z: float = np.sqrt(0.5),\n    betas: np.ndarray = np.array([-4.3, 1.0]),\n    sigmas: np.ndarray = np.array([1.0]),\n) -&gt; FracNoDemogSimulatedData:\n    \"\"\"\n    Simulate FRAC data with endogenous random-coefficient regressors.\n\n    Returns:\n        FracNoDemogSimulatedData: Simulated dataset ready for FRAC estimation.\n    \"\"\"\n    n_X1 = n_X1_exo + n_X1_endo\n    n_X2 = n_X2_exo + n_X2_endo\n    names_X1_exo = [\"constant\"]\n    if n_X1_exo &gt; 1:\n        names_X1_exo += [f\"x_{i + 1}\" for i in range(n_X1_exo - 1)]\n    names_X1_endo = []\n    names_X1_endo = [f\"x_{i}\" for i in range(n_X1_exo, n_X1)]\n    names_X2_exo = [f\"x_{i + 1}\" for i in range(n_X2_exo)]\n    names_X2_endo = [f\"x_{i + 1}\" for i in range(n_X2_exo, n_X2)]\n\n    return FracNoDemogSimulatedData(\n        T=T,\n        J=J,\n        names_X1_exo=names_X1_exo,\n        names_X1_endo=names_X1_endo,\n        names_X2_exo=names_X2_exo,\n        names_X2_endo=names_X2_endo,\n        n_Z=n_Z,\n        sigma_x=sigma_x,\n        sigma_xi=sigma_xi,\n        rho_x_z=rho_x_z,\n        rho_x_xi=rho_x_xi,\n        betas=betas,\n        sigmas=sigmas,\n    )\n</code></pre>"}]}